"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getEncodingInfo = exports.detectEncodingFromBuffer = exports.detectEncodingByBOMFromBuffer = exports.iconvEncode = exports.iconvDecode = exports.toNodeEncoding = exports.encodingExists = exports.toCanonicalName = exports.toIconvLiteEncoding = exports.isUTF8 = exports.UTF8_BOM = exports.UTF16le_BOM = exports.UTF16be_BOM = exports.UTF16le = exports.UTF16be = exports.UTF8_with_bom = exports.UTF8 = void 0;
const tslib_1 = require("tslib");
/* ---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
const iconv_lite_1 = tslib_1.__importDefault(require("iconv-lite"));
const const_1 = require("./const");
exports.UTF8 = 'utf8';
exports.UTF8_with_bom = 'utf8bom';
exports.UTF16be = 'utf16be';
exports.UTF16le = 'utf16le';
exports.UTF16be_BOM = [0xfe, 0xff];
exports.UTF16le_BOM = [0xff, 0xfe];
exports.UTF8_BOM = [0xef, 0xbb, 0xbf];
const ZERO_BYTE_DETECTION_BUFFER_MAX_LEN = 512; // number of bytes to look at to decide about a file being binary or not
const AUTO_ENCODING_GUESS_MAX_BYTES = 512 * 128; // set an upper limit for the number of bytes we pass on to jschardet
function isUTF8(encoding) {
    if (encoding) {
        return toIconvLiteEncoding(encoding) === exports.UTF8;
    }
    return false;
}
exports.isUTF8 = isUTF8;
const SUPPORT_ENCODINGS_TO_ICONV_ENCODINGS = {
    ibm866: 'cp866',
    big5: 'cp950',
    utf8bom: 'utf8',
};
function toIconvLiteEncoding(encodingName) {
    const normalizedEncodingName = encodingName.replace(/[^a-zA-Z0-9]/g, '').toLowerCase();
    const mapped = SUPPORT_ENCODINGS_TO_ICONV_ENCODINGS[normalizedEncodingName];
    return mapped || normalizedEncodingName;
}
exports.toIconvLiteEncoding = toIconvLiteEncoding;
/**
 * The encodings that are allowed in a settings file don't match the canonical encoding labels specified by WHATWG.
 * See https://encoding.spec.whatwg.org/#names-and-labels
 * Iconv-lite strips all non-alphanumeric characters, but ripgrep doesn't. For backcompat, allow these labels.
 */
function toCanonicalName(enc) {
    switch (enc) {
        case 'shiftjis':
            return 'shift-jis';
        case 'utf16le':
            return 'utf-16le';
        case 'utf16be':
            return 'utf-16be';
        case 'big5hkscs':
            return 'big5-hkscs';
        case 'eucjp':
            return 'euc-jp';
        case 'euckr':
            return 'euc-kr';
        case 'koi8r':
            return 'koi8-r';
        case 'koi8u':
            return 'koi8-u';
        case 'macroman':
            return 'x-mac-roman';
        case 'utf8bom':
            return 'utf8';
        default: {
            const m = enc.match(/windows(\d+)/);
            if (m) {
                return 'windows-' + m[1];
            }
            return enc;
        }
    }
}
exports.toCanonicalName = toCanonicalName;
async function encodingExists(encoding) {
    return iconv_lite_1.default.encodingExists(toNodeEncoding(encoding));
}
exports.encodingExists = encodingExists;
function toNodeEncoding(enc) {
    if (enc === exports.UTF8_with_bom || enc === null) {
        return exports.UTF8; // iconv does not distinguish UTF 8 with or without BOM, so we need to help it
    }
    return enc;
}
exports.toNodeEncoding = toNodeEncoding;
/**
 * nodejs 内置的 Buffer 转换编码不支持 GBK，使用第三方的 iconv-lite
 * @param buffer Uint8Array | Buffer
 * @param encoding 传入的是 SUPPORTED_ENCODINGS 已有的键值（已通过 tests case 的）
 */
function iconvDecode(buffer, encoding) {
    encoding = toIconvLiteEncoding(encoding);
    return iconv_lite_1.default.decode(buffer, encoding);
}
exports.iconvDecode = iconvDecode;
function iconvEncode(content, encoding) {
    encoding = toIconvLiteEncoding(encoding);
    return iconv_lite_1.default.encode(content, encoding);
}
exports.iconvEncode = iconvEncode;
function encodeLatin1(buffer) {
    let result = '';
    // eslint-disable-next-line @typescript-eslint/prefer-for-of
    for (let i = 0; i < buffer.length; i++) {
        result += String.fromCharCode(buffer[i]);
    }
    return result;
}
function detectEncodingByBOMFromBuffer(buffer, bytesRead) {
    if (!buffer || bytesRead < exports.UTF16be_BOM.length) {
        return null;
    }
    const b0 = buffer.readUInt8(0);
    const b1 = buffer.readUInt8(1);
    // UTF-16 BE
    if (b0 === exports.UTF16be_BOM[0] && b1 === exports.UTF16be_BOM[1]) {
        return exports.UTF16be;
    }
    // UTF-16 LE
    if (b0 === exports.UTF16le_BOM[0] && b1 === exports.UTF16le_BOM[1]) {
        return exports.UTF16le;
    }
    if (bytesRead < exports.UTF8_BOM.length) {
        return null;
    }
    const b2 = buffer.readUInt8(2);
    // UTF-8
    if (b0 === exports.UTF8_BOM[0] && b1 === exports.UTF8_BOM[1] && b2 === exports.UTF8_BOM[2]) {
        return exports.UTF8_with_bom;
    }
    return null;
}
exports.detectEncodingByBOMFromBuffer = detectEncodingByBOMFromBuffer;
// we explicitly ignore a specific set of encodings from auto guessing
// - ASCII: we never want this encoding (most UTF-8 files would happily detect as
//          ASCII files and then you could not type non-ASCII characters anymore)
// - UTF-16: we have our own detection logic for UTF-16
// - UTF-32: we do not support this encoding in VSCode
const IGNORE_ENCODINGS = ['ascii', 'utf-16', 'utf-32'];
async function guessEncodingByBuffer(buffer) {
    // lazy load
    const jschardet = await import('jschardet');
    // ensure to limit buffer for guessing due to https://github.com/aadsm/jschardet/issues/53
    const limitedBuffer = buffer.slice(0, AUTO_ENCODING_GUESS_MAX_BYTES);
    // before guessing jschardet calls toString('binary') on input if it is a Buffer,
    // since we are using it inside browser environment as well we do conversion ourselves
    // https://github.com/aadsm/jschardet/blob/v2.1.1/src/index.js#L36-L40
    const binaryString = encodeLatin1(limitedBuffer.buffer);
    const guessed = jschardet.detect(binaryString);
    if (!guessed || !guessed.encoding) {
        return null;
    }
    const enc = guessed.encoding.toLowerCase();
    if (0 <= IGNORE_ENCODINGS.indexOf(enc)) {
        return null; // see comment above why we ignore some encodings
    }
    return toIconvLiteEncoding(guessed.encoding);
}
function detectEncodingFromBuffer(buffer, autoGuessEncoding) {
    const bytesRead = buffer.byteLength;
    // Always first check for BOM to find out about encoding
    let encoding = detectEncodingByBOMFromBuffer(buffer, bytesRead);
    // Detect 0 bytes to see if file is binary or UTF-16 LE/BE
    // unless we already know that this file has a UTF-16 encoding
    let seemsBinary = false;
    if (encoding !== exports.UTF16be && encoding !== exports.UTF16le && buffer) {
        let couldBeUTF16LE = true; // e.g. 0xAA 0x00
        let couldBeUTF16BE = true; // e.g. 0x00 0xAA
        let containsZeroByte = false;
        // This is a simplified guess to detect UTF-16 BE or LE by just checking if
        // the first 512 bytes have the 0-byte at a specific location. For UTF-16 LE
        // this would be the odd byte index and for UTF-16 BE the even one.
        // Note: this can produce false positives (a binary file that uses a 2-byte
        // encoding of the same format as UTF-16) and false negatives (a UTF-16 file
        // that is using 4 bytes to encode a character).
        for (let i = 0; i < bytesRead && i < ZERO_BYTE_DETECTION_BUFFER_MAX_LEN; i++) {
            const isEndian = i % 2 === 1; // assume 2-byte sequences typical for UTF-16
            const isZeroByte = buffer.readUInt8(i) === 0;
            if (isZeroByte) {
                containsZeroByte = true;
            }
            // UTF-16 LE: expect e.g. 0xAA 0x00
            if (couldBeUTF16LE && ((isEndian && !isZeroByte) || (!isEndian && isZeroByte))) {
                couldBeUTF16LE = false;
            }
            // UTF-16 BE: expect e.g. 0x00 0xAA
            if (couldBeUTF16BE && ((isEndian && isZeroByte) || (!isEndian && !isZeroByte))) {
                couldBeUTF16BE = false;
            }
            // Return if this is neither UTF16-LE nor UTF16-BE and thus treat as binary
            if (isZeroByte && !couldBeUTF16LE && !couldBeUTF16BE) {
                break;
            }
        }
        // Handle case of 0-byte included
        if (containsZeroByte) {
            if (couldBeUTF16LE) {
                encoding = exports.UTF16le;
            }
            else if (couldBeUTF16BE) {
                encoding = exports.UTF16be;
            }
            else {
                seemsBinary = true;
            }
        }
    }
    // Auto guess encoding if configured
    if (autoGuessEncoding && !seemsBinary && !encoding && buffer) {
        return guessEncodingByBuffer(buffer.slice(0, bytesRead)).then((guessedEncoding) => ({
            seemsBinary: false,
            encoding: guessedEncoding,
        }));
    }
    return { seemsBinary, encoding };
}
exports.detectEncodingFromBuffer = detectEncodingFromBuffer;
function getEncodingInfo(encoding) {
    if (!encoding) {
        return null;
    }
    const result = const_1.SUPPORTED_ENCODINGS[encoding] || {};
    return {
        id: encoding,
        labelLong: result.labelLong || encoding,
        labelShort: result.labelShort || encoding,
    };
}
exports.getEncodingInfo = getEncodingInfo;
//# sourceMappingURL=encoding.js.map